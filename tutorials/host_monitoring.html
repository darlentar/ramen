<html>
  <head>
    <meta charset="utf-8">
    <base href="https://rixed.github.io/ramen/">
    <link rel="stylesheet" href="style.css" type="text/css" media="screen">
    <title>Ramen Documentation</title>
  </head>
<body>

  <script type="application/json" class="js-hypothesis-config">{ "showHighlights": "whenSidebarOpen" }</script>
  <script src="https://hypothes.is/embed.js" async></script>

  <div id="menu">
    <a href="index.html">Overview</a>
    <a href="download.html">Downloading</a>
    <a href="build.html">Building</a>
    <a href="tutorials.html">Tutorials</a>
    <a href="design.html">Design</a>
    <a href="roadmap.html">Roadmap</a>
    <a href="man.html">Command line reference</a>
    <a href="language_reference.html">Language reference</a>
    <a href="blog.html">Blog posts</a>
  </div>
<h1>Host Monitoring in 15 minutes</h1>

<h2>Starting up</h2>

<h3>Using the Docker image</h3>

<p>The docker image is about 150MiB compressed. We are going to bind the <code class="prettyprint">ramen</code> directory in your home, so make sure $HOME/ramen does not exist. We are also going to redirect Ramen graphite impersonator, <em>collectd</em> and <em>netflow</em> UDP ports into the docker image. Run:</p>

<pre class="prettyprint">
$ docker run --name=ramen-test -v $HOME/ramen:/ramen -p 25826:25826/udp -p 2055:2055/udp -p 29380:29380/tcp rixed/ramen
</pre>

<p>...and continue this tutorial from another terminal.</p>

<p>Redirecting the ports is optional: The docker image comes with <a href="https://collectd.org/">collectd</a> and <a href="http://fprobe.sourceforge.net/">fprobe</a> daemons that will monitor the container itself. That is not super interesting but it's enough to get some data in. You could also point external collectd and netflow sources to these ports for real world data.</p>

<p>From now on we will run the `ramen` program through docker so often that a shortcut is in order:</p>

<pre class="prettyprint">
$ alias ramen "docker exec ramen-test ramen"
</pre>

<h3>Installing more probes</h3>

<p>Skip that section if you are happy with using only internally generated metrics for the duration of this tutorial.</p>

<h4>Installing collectd</h4>

<p><code class="prettyprint">aptitude install collectd</code>.</p>

<p>Edit <code class="prettyprint">/etc/collectd/collectd.conf</code> (or the equivalent, such as <code class="prettyprint">/usr/local/etc/collectd.conf</code> if brewed on mac OS), uncomment `LoadPlugin network` and make sure the stats will be sent to your server running ramen. For now let's say you run collectd and ramen on the same host, that means you must have this configuration for the network plugin:</p>

</pre>
<Plugin network>
  Server "127.0.0.1" "25826"
</Plugin>
</pre>

<p>WARNING: Replace "127.0.0.1" with the actual address of your host if collectd runs elsewhere.</p>

<p>Then you can restart collectd (<code class="prettyprint">systemctl restart collectd.service</code> or <code class="prettyprint">/usr/local/sbin/collectd -f -C /usr/local/etc/collectd.conf</code> or whatever works for you).</p>

<h4>Sending more netflow to Ramen</h4>

<p>The docker image comes with an internal netflow source that will send flow information to Ramen about the traffic taking place inside the container.  This is of course of little use for monitoring but is enough to get some data.</p>

<p>If you already have access to a switch that can emit netflow statistics then you could direct them to the container port 2055 for more interesting data.</p>

<h2>Getting some data in</h2>

<p>Ramen won't do anything at all if we do not tell it to do it. At first we are going to collect netflow statistics and turn it into a small network traffic dashboard.</p>

<p>Let's create a subdirectory <code class="prettyprint">ramen/sources</code> and create there a file named <code class="prettyprint">demo.ramen</code> with a few instructions:</p>

<pre class="prettyprint">
$ mkdir $HOME/ramen/sources
$ cat &gt; $HOME/ramen/sources/demo.ramen &lt;&lt;EOF
-- Ingest some data from the outside world (this is just a comment)
DEFINE netflow AS listen for netflow;
DEFINE collectd AS listen for collectd;
EOF
$
</pre>

<p>This program defines two <em>functions</em> named <code class="prettyprint">netflow</code> and <code class="prettyprint">collectd</code>. The construct <code class="prettyprint">listen for ...</code> means to open a socket and decode incoming messages for the named protocols, and turn that into a stream of data. That's how we are going to get some data in for now.</p>

<p>This file can then be compiled with (the path is as seen by Ramen from within the docker image!):</p>

<pre class="prettyprint">
$ ramen compile sources/demo.ramen --as demo
Parsing program demo
Typing program demo
Compiling program demo
Compiling "ramen_root/demo_params_v48.ml"
Compiling "ramen_root/demo_e202c4a9d0fb42089406fe7539688b2b_v48.ml"
Compiling "ramen_root/demo_d388e90d7b555a745a23719a13b26293_v48.ml"
Linking "ramen_root/demo_casing_v48.ml"
</pre>

<p>...and you should now have a <code class="prettyprint">demo.x</code> file. Let's ask Ramen to run it:</p>

<pre class="prettyprint">
$ ramen run sources/demo.x
</pre>

<p>A quick look at `ramen ps` confirms that it's indeed running:</p>

<pre class="prettyprint">
$ ramen ps --pretty
operation     | #in | #selected | #out | #groups | last out | min event time | max event time | CPU   | wait in | wait out | heap    | max heap | volume in | volume out | startup time         | #parents | #children | signature                        |
demo/collectd | n/a |       n/a |    0 |     n/a |      n/a |            n/a |            n/a | 0.012 |       0 |        0 | 3932160 |  3932160 |         0 |          0 | 2018-12-13T10h52m59s |        0 |         0 | d388e90d7b555a745a23719a13b26293 |
demo/netflow  | n/a |       n/a |    0 |     n/a |      n/a |            n/a |            n/a | 0.012 |       0 |        0 | 3932160 |  3932160 |         0 |          0 | 2018-12-13T10h52m59s |        0 |         0 | e202c4a9d0fb42089406fe7539688b2b |
</pre>

<h2>Getting data out</h2>

<p>Let's see what the netflow messages are turned into:</p>

<pre class="prettyprint">
$ ramen tail -f --with-header demo/netflow
#source,start,stop,seqnum,engine_type,engine_id,sampling_type,sampling_rate,src,dst,next_hop,src_port,dst_port,in_iface,out_iface,packets,bytes,tcp_flags,ip_proto,ip_tos,src_as,dst_as,src_mask,dst_mask
1219,176.59.205.59,0,0,1045,0,0,0,17,0,0.0.0.0,0,2,0,0,33865509,"172.17.0.1:56098",5.135.156.187,0,0,3760,1544698921.22,1544698926.91,0
924,5.135.156.187,0,0,3760,0,0,0,17,0,0.0.0.0,0,7,0,0,33865509,"172.17.0.1:56098",76.69.117.5,0,0,51413,1544698925.27,1544698926.31,0
332,173.212.202.22,0,0,6929,0,0,0,17,0,0.0.0.0,0,1,0,0,33865509,"172.17.0.1:56098",5.135.156.187,0,0,3760,1544698925.71,1544698925.71,0
125,5.135.156.187,0,0,3760,0,0,0,17,0,0.0.0.0,0,1,0,0,33865509,"172.17.0.1:56098",173.212.202.22,0,0,6929,1544698925.7,1544698925.7,0
52,46.4.105.12,0,0,445,0,0,0,6,0,0.0.0.0,0,1,0,0,7497501,"172.17.0.1:57909",123.17.109.95,0,0,57566,1544698609.67,1544698609.67,2
40,46.4.105.4,0,0,24242,0,0,0,6,0,0.0.0.0,0,1,0,0,7497501,"172.17.0.1:57909",78.128.112.10,0,0,50976,1544698607.55,1544698607.55,2
120,46.4.104.236,0,0,80,0,0,0,6,0,0.0.0.0,0,2,0,0,7497501,"172.17.0.1:57909",148.251.75.227,0,0,26204,1544698605.16,1544698608.17,2
40,46.4.125.34,0,0,7100,0,0,0,6,0,0.0.0.0,0,1,0,0,7497501,"172.17.0.1:57909",125.64.94.197,0,0,33137,1544698609.7,1544698609.7,2
40,46.4.118.133,0,0,1281,0,0,0,6,0,0.0.0.0,0,1,0,0,7497501,"172.17.0.1:57909",176.119.7.18,0,0,57163,1544698610.01,1544698610.01,2
40,46.4.118.133,0,0,7100,0,0,0,6,0,0.0.0.0,0,1,0,0,7497501,"172.17.0.1:57909",125.64.94.197,0,0,46701,1544698606.47,1544698606.47,2
^C
$
</pre>

<p>Let's now extract a timeseries for the <code class="prettyprint">bytes</code> field. Assuming you are using GNU date and a Bourne-like shell, you could type:</p>

<pre class="prettyprint">
$ ramen timeseries \
    --since $(date -d '10 minutes ago' '+%s') \
    --until $(date -d '1 minutes ago' '+%s') \
    --with-header --num-points 9 --consolidation sum \
    demo/netflow bytes
#Time,bytes
2018-12-13T11h34m15s,&lt;NULL&gt;
2018-12-13T11h35m15s,&lt;NULL&gt;
2018-12-13T11h36m15s,37213.5588409
2018-12-13T11h37m15s,348552.509063
2018-12-13T11h38m15s,411183.370782
2018-12-13T11h39m15s,519981.395792
2018-12-13T11h40m15s,643904.305475
2018-12-13T11h41m15s,636835.757926
2018-12-13T11h42m15s,173121.564614
</pre>

<p>Note: you may want to wait a bit for netflow records t be received before running this.</p>

<p>The <code class="prettyprint">consolidation</code> option specify how to fit events into the time buckets, and possible values are <code class="prettyprint">min</code>, <code class="prettyprint">max</code>, <code class="prettyprint">avg</code> (the default) and <code class="prettyprint">sum</code>. Here we are accumulating traffic volumes from different sources so the only meaningful way to combine those volumes is to sum them.</p>

<p>That timeseries of course could be piped into any dashboarding program, such as the venerable <a href="http://www.gnuplot.info">gnuplot</a> (don't worry, we will use <a href="https://grafana.com">grafana</a> in a minute):</p>

<pre class="prettyprint">
$ while sleep 10; do \
    ramen timeseries \
      --since $(date -d '31 minutes ago' '+%s') \
      --until $(date -d '1 minute ago' '+%s') \
      --num-points 30 --separator ' ' --null 0 --consolidation sum \
      demo/netflow bytes 2>/dev/null | \
    gnuplot -p -e "set timefmt '%Y-%m-%dT%H:%M:%S'; set xdata time; set format x '%H:%M'; \
      set terminal dumb $COLUMNS,$LINES; \
      plot '&lt; cat -' using 1:2 with lines title 'Bytes'";
  done

    4e+07 +-+-+--+---+--+---+--+---+--+---+--+---+************-+---+--+---+--+---+--+---+--+---+--+---+--+---+--+-+-+
          +          +         +          +       * +        * +          +         +          +         +          +
  3.5e+07 +-+                                    *            *                                       Bytes *******-+
          |                                      *            *                                                     |
          |                                     *              *                                                    |
    3e+07 +-+                                   *              *                                                  +-+
          |                                    *                *                                                   |
  2.5e+07 +-+                                  *                **                                                +-+
          |                                   *                   **                                                |
          |                                   *                                                                     |
    2e+07 +-+                                 *                     ***                                           +-+
          |                                  *                         ***********                                  |
  1.5e+07 +-+                                *                                    *                               +-+
          |                                  *                                    *                                 |
          |                                  *                                     *                                |
    1e+07 +-+                               *                                      *                              +-+
          |                                 *                                       *                               |
    5e+06 +-+                               *                                       *                             +-+
          |                                 *                                       *                               |
          +          +         +          +*        +          +          +         +*         +         +          +
        0 +*********************************-+---+--+---+--+---+---+--+---+--+---+--+******************************-+
        11:30      11:33     11:36      11:39     11:42      11:45      11:48     11:51      11:54     11:57      12:00
</pre>

<p>Ok, now that we are confident we know how to get some data in and out, let's have a look at what we can do with the data in between.</p>

<h2>Ramen Programs and Functions</h2>

<p>Programs are sets of functions. A function can be of several types: listening to some network port for some known protocol (such as collectd or netflow) is one of them. Reading data from CSV files is another. But in general though, functions will take their input from other functions output, thus creating a tree of functions ultimately computing the signal one want to alert on. A function output (and input) is thus a never-ending stream of messages, composed of several named fields of given types and that we call <em>tuples</em> or <em>events</em>. For instance, here is a tuple:</p>

<table>
<tr>
  <th>time</th>
  <th>host</th>
  <th>interface</th>
  <th>sent</th>
  <th>received</th>
</tr><tr>
  <td>1507295705.54</td>
  <td>www45</td>
  <td>em0</td>
  <td>749998080</td>
  <td>1821294592</td>
</tr>
</table>

<p>A function can have zero, one or several parents and children. All children receive a full copy of the output.</p>

<p>Programs are the smallest unit that can be created, started and stopped. A function from a program might read the output of a function defined in another program, as long as it is already running when that new program is run.</p>

<p>Functions and programs have names. Program names must be globally unique while function names need only be unique within the program they belong to. The <em>fully qualified</em> name of an function is the name of the program it belongs to, followed by a slash ("/"), followed by the name of the function. Consequently, the slash character is not allowed in an function name.</p>

<p>For instance, "base/per_hosts/hourly_traffic" is the fully qualified name of the function "hourly_traffic" in the program named "base/per_hosts". Notice that the slash ("/") in the program name is just a convention with no particular meaning.</p>

<p>For now we have a single program named "demo" containing only two functions.</p>

<h2>Computing Memory Consumption</h2>

<p>Monitoring usually involves three phases:</p>

<ol>
<li>Collecting all possible data (that's what we have just done above);</li>
<li>Turning that data into meaningful information;</li>
<li>Finally alert on that information.</li>
</ol>

<p>We are now going to see how we could turn our netflows and collectd messages into something useful.</p>

<p>Collectd events are very fine grained and one may want to build a more synthetic view of the state of some subsystem. Let's start with memory: Instead of having individual events with various bits of information about many subsystems, let's try to build a stream representing, at a given time, how memory is allocated for various usage.</p>

<p>So to begin with, let's filter the events generated by collectd memory probes.  Let's write a new program and call it <code class="prettyprint">hosts.ramen</code>, for we will monitor hosts health in it.</p>

<pre class="prettyprint">
DEFINE memory AS
  SELECT * FROM demo/collectd WHERE COALESCE(plugin = "memory", false);
</pre>

<p>Without going too deep into Ramen syntax, the intended meaning of this simple function should be clear: we want to filter the tuples according to their <code class="prettyprint">plugin</code> field and keep only those originating from the "memory" plugin. The <code class="prettyprint">COALESCE</code> function is here because a <code class="prettyprint">WHERE</code> clause is not allowed to be NULL, but the <code class="prettyprint">plugin</code> field can be NULL.</p>

<p>Save, compile and run it:</p>

<pre class="prettyprint">
$ ramen compile sources/hosts.ramen --as hosts
$ ramen run sources/hosts.x
</pre>

<p>You might notice (<code class="prettyprint">ramen tail hosts/memory</code>) that this plugin only sets one value and also that the <code class="prettyprint">type_instance</code> field contains the type of memory this value refers to.  Apart from that, most fields are useless. We could therefore make this more readable by changing its function into the following, enumerating the fields we want to keep (and implicitly discarding the others):</p>

<pre class="prettyprint">
DEFINE memory AS
  SELECT start, host, type_instance, value
  FROM demo/collectd
  WHERE COALESCE(plugin = "memory", false);
</pre>

<p>The output is now easier to read; it should look something like this:</p>

<pre class="prettyprint">
$ ramen tail hosts/memory --with-header
#time,host,type_instance,value
1522945763.3,"poum","used",4902309888
1522945763.3,"poum","cached",17255350272
1522945763.3,"poum","buffered",2819915776
1522945763.3,"poum","free",763043840
1522945763.3,"poum","slab_unrecl",97742848
1522945763.3,"poum","slab_recl",7081136128
1522945773.3,"poum","used",4902801408
1522945773.3,"poum","cached",17255350272
1522945773.3,"poum","buffered",2819915776
1522945773.3,"poum","slab_recl",7081103360
1522945773.3,"poum","slab_unrecl",97460224
1522945773.3,"poum","free",762867712
...
</pre>

<p>On your own system, other "type instances" might appear; please adapt accordingly as you read along.</p>

<p>There is still a major annoyance though: we'd prefer to have the values for each possible "type instances" (here: the strings "free", "used", "cached" and so on) as different columns of a single row, instead of spread amongst several rows, so that we know at each point in time what the memory usage is like.  Since we seem to receive one report form collectd every 10 seconds or so, a simple way to achieve this would be to accumulate all such reports for 30 seconds and then output a single tuple every 30 seconds with one column per known "type instance".</p>

<p>For this, we need to "aggregate" several tuples together, using a <code class="prettyprint">GROUP BY</code> clause. Try this:</p>

<pre class="prettyprint">
DEFINE memory AS
  SELECT
    MIN start AS start,
    MAX start AS stop,
    host,
    COALESCE (type_instance, "") AS _type,
    AVG (IF _type = "free" THEN value ELSE 0) AS free,
    AVG (IF _type = "used" THEN value ELSE 0) AS used,
    AVG (IF _type = "cached" THEN value ELSE 0) AS cached,
    AVG (IF _type = "buffered" THEN value ELSE 0) AS buffered,
    AVG (IF _type LIKE "slab%" THEN value ELSE 0) AS slab
  FROM demo/collectd
  WHERE COALESCE (plugin = "memory", false)
  GROUP BY host, start // 30
  COMMIT AFTER in.start &gt; out.start + 30;
</pre>

<p>Let's quickly go through some bits of this example that might not be immediately clear.</p>

<ul>
<li>Most of the fields have been given a name explicitly with the <code class="prettyprint">AS</code> keyword;</li>
<li>We compute both the start and stop of each event by taking the minimum and maximum of the timestamp present in collectd, because we need the events to have a duration (timeseries extraction should consider that default stop is the next start but that's still TBD);</li>
<li>Any field name starting with underscore, such as <code class="prettyprint">_type</code> in this example, is private to the function and not part of the actual output;</li>
<li><code class="prettyprint">//</code> is the integer division, this here we are grouping by host names and slices of 30 seconds;</li>
<li>The COMMIT clause tells ramen when to stop aggregating a group and output the result;</li>
<li>The field of new incoming tuples are accessible via the <code class="prettyprint">in.*</code> record ; this is also the default so we do not have to write <code class="prettyprint">in.value</code> but can merely write <code class="prettyprint">value</code> instead. But in the COMMIT clause we need to refer to both the incoming tuple and the aggregated <code class="prettyprint">out</code> tuple, so we make this explicit;</li>
<li>Beside <code class="prettyprint">in</code> and <code class="prettyprint">out</code> there are a few more rarely used records that are described in the <a href="language_reference.html#tuple-field-names">manual</a>;</li>
</ul>

<h2>Dashboarding</h2>

<p>Let's have a look at this using Grafana.</p>

<p>Run grafana:</p>

<pre class="prettyprint">
$ docker run -d -p 3000:3000 grafana/grafana
</pre>

<p>Then connect to it (<a href="http://localhost:3000/">maybe?</a>), log in and go to the settings to add a data source. Select <em>Graphite</em>, and set the URL as <code class="prettyprint">http://the.ip.of.the.machine:29380/</code>, selecting to access it from the browser (the simplest configuration). Click and voilà.</p>

<p>Now create a dashboard, add a graph, and you should be able to graph these tables as if they were from graphite (with the exception that functions are not supported yet. For instance, you could graph <code class="prettyprint">hosts.memory.*</code>.</p>

<h2>Alerting On Low Memory</h2>

<p>Ramen only ways to notify the external world of some condition is the <code class="prettyprint">NOTIFY</code> clause that takes an HTTP URL as a parameter and that will get (as in <code class="prettyprint">HTTP GET</code>) that URL each time the function commits a tuple.</p>

<p>As a simple example, let's say we want to be alerted whenever the "used" memory grows beyond 50% of the total.</p>

<p>We can use the <code class="prettyprint">NOTIFY</code> keyword to reach out to some imaginary alerting service. Let's add to <code class="prettyprint">hosts.ramen</code> an function named <code class="prettyprint">memory_alert</code>, defined like this:</p>

<pre class="prettyprint">
DEFINE memory_alert AS
  FROM memory
  SELECT
    time, host,
    free + used + cached + buffered + slab AS total,
    free * 100 / total AS used_ratio
  GROUP BY host
  COMMIT AFTER used_ratio &gt; 50
  NOTIFY "http://imaginary-alerting.com/notify?title=RAM%20is%20low%20on%20${host}&time=${time}&text=Memory%20on%20${host}%20is%20filled%20up%20to%20${used_ratio}%25"
  EVENT STARTING AT time WITH DURATION 30;
</pre>

<p>Notice that we can reuse the field <code class="prettyprint">total</code> after it has been defined in the select clause, which comes rather handy when building complex values as it allows to name intermediary result.</p>

<p>NOTE: Should you not want such an intermediary result to be actually part of the output tuple, you would have to prepend its name with an underscore ; as a corollary, any field which name starts with an underscore will not appear in the output. Those fields are called "private fields".</p>

<p>Notice the <code class="prettyprint">NOTIFY</code> clause: it just needs an URL within which actual field values can be inserted.</p>

<p>Let's compile that new program.</p>

</pre>
In function memory_alert: comparison (>) must not be nullable
</pre>

<p>Wait, what? Now the compiler is complaining that <code class="prettyprint">used_ratio</code> can be NULL?  Have you noticed that all of our memory values could be NULL? That's typically the kind of surprise Ramen type system is designed to catch early.</p>

<p>Of course, collectd "type_instance" field is nullable, so is the <code class="prettyprint">IF type_instance = "whatever"</code> conditional, so are each of the averaged memory volumes. We could wrap each use of type_instance into a <code class="prettyprint">COALESCE</code> function but that would be tedious. Rather, let's put in practice our new knowledge about private fields. Turn the memory function into:</p>

<pre class="prettyprint">
DEFINE memory AS
  SELECT
    MIN time AS time,
    host,
    COALESCE (type_instance, "") AS _type,
    AVG (IF _type = "free" THEN value ELSE 0) AS free,
    AVG (IF _type = "used" THEN value ELSE 0) AS used,
    AVG (IF _type = "cached" THEN value ELSE 0) AS cached,
    AVG (IF _type = "buffered" THEN value ELSE 0) AS buffered,
    AVG (IF _type LIKE "slab%" THEN value ELSE 0) AS slab
  FROM demo/collectd
  WHERE COALESCE (plugin = "memory", false)
  GROUP BY host, time // 30
  COMMIT AFTER in.time &gt; out.time + 30
  EVENT STARTING AT time WITH DURATION 30;
</pre>

<p>...and then everything should compile and run.</p>

<p>What will happen whenever the memory usage ratio hit the threshold is that the imaginary alerting system will receive a notification from Ramen.  It would be nice if we could also tell it when the memory usage goes back below the threshold.  Let's add a boolean <code class="prettyprint">firing</code> parameter for that purpose.</p>

<p>Edit the "memory alert" function into this:</p>

<pre class="prettyprint">
DEFINE memory_alert AS
  FROM hosts/memory
  SELECT
    time, host,
    free + used + cached + buffered + slab AS total,
    free * 100 / total AS used_ratio,
    used_ratio &gt; 50 AS firing
  GROUP BY host
  COMMIT AND KEEP ALL WHEN COALESCE (out.firing <> previous.firing, false)
  NOTIFY "http://imaginary-alerting.com/notify?firing=${firing}&title=RAM%20is%20low%20on%20${host}&time=${time}&text=Memory%20on%20${host}%20is%20filled%20up%20to%20${used_ratio}%25"
  EVENT STARTING AT time WITH DURATION 30;
</pre>

<p>There should be little surprise but for the commit clause.</p>

<p>There we see the "previous" tuple for the first time. It's similar to the "out" tuple, but the "out" tuple refers to the tuple that's actualy in construction (the one that would be emitted right now if that commit clauses says so) whereas the "previous" tuple refers to the former value of that tuple (the one that would have been emitted the last time we added something to that aggregation group, should the commit clause said so). The out tuple always have a value, but the previous one not necessarily: indeed, when this group have just been created there is no "last time". In that case, all the previous tuple fields would be NULL (regardless of their normal nullability). Therefore the <code class="prettyprint">COALESCE</code>.</p>

<p>What that <code class="prettyprint">COMMIT AND KEEP ALL</code> does is to instruct Ramen not to delete the group when the tuple is output (the default behavior is to discard the group once it's been output).  <code class="prettyprint">KEEP ALL</code> means that the group should stay untouched, as if it hasn't been output at all. Otherwise we would loose the memory of what was the last output tuple for this host (next time we hear about that host, a new group would be created and <code class="prettyprint">previous.firing</code> would be NULL). In contrast, <code class="prettyprint">KEEP ALL</code> will never delete the groups, so we will have as many groups as we have hosts to save their last firing state, which is reasonable.</p>

<p>So here we send a notification only when the value of <code class="prettyprint">firing</code> changes.  Note that in production you likely want to use an hysteresis. There are several ways to do that, but let's leave it as an exercise.</p>

<h2>Monitoring Netflows</h2>

<p>Let's now turn into netflows.</p>

<p>Have a look at the output of the <code class="prettyprint">demo/netflow</code> function and, armed with <a href="https://www.cisco.com/c/en/us/td/docs/net_mgmt/netflow_collection_engine/3-6/user/guide/format.html#wp1006186">netflow format reference</a>, see if you can make sense of that data.</p>

<p>If you are not already familiar with this, then you just have to know that netflows are bytes, packets and flag counts for each "flow" defined roughly as the IP socket pair (ip protocol, addresses and ports), and a "route" inside the switch from the inbound to outbound interface. Switches will send those records regularly every few minutes so that we know the volume of the traffic per socket, that we can aggregate per subnets or per switch interfaces, and so on.</p>

<p>What we are ultimately interested in, for monitoring purpose, will typically be:</p>

<ul>
<li>Is any switch interface close to saturation?</li>
<li>Is the total traffic from/to a given subnet within the expected range?</li>
<li>Is a link down?</li>
<li>Are there any traffic from a given subnet to another given subnet for a given port (for instance, from internal to external port 25)?</li>
<li>Is there some DDoS going on? Or some other malicious pattern?</li>
</ul>

<p>We will see how to compute some of those.</p>

<h3>Per interface traffic</h3>

<p>Let's start by aggregating all traffic per switch interfaces.</p>

<p>Netflow has 3 fields of interest here: "source", which is the IP address of the netflow emitter (say, a switch), and "in_iface" and "out_iface", which identifies the interfaces from which the flow entered and exited the switch.</p>

<p>To build a per interface aggregate view we therefore have to split each flow into two, saying that the traffic that have been received on interface X and emitted on interface Y count as traffic for interface X and traffic for interface Y, counting indifferently incoming and outgoing traffic.</p>

<p>Let's therefore create a new program file named "traffic.ramen", with two functions that we could name respectively "inbound" and "outbound":</p>

<pre class="prettyprint">
DEFINE inbound AS
  SELECT source, first, last, bytes, packets, in_iface AS iface
  FROM demo/netflow;
</pre>

<p>...and...</p>

<pre class="prettyprint">
DEFINE outbound AS
  SELECT source, first, last, bytes, packets, out_iface AS iface
  FROM demo/netflow;
</pre>

<p>Both will read the netflows and output flows with a single <code class="prettyprint">iface</code> field for both incoming and outgoing traffic. We can then read from both those functions and have a single view of all traffic going through a given interface (in or out).</p>

<p>Let's jut do that. In an function named "total", grouping by interface (that is, by <code class="prettyprint">source</code> and <code class="prettyprint">iface</code>) and aggregating the traffic (<code class="prettyprint">bytes</code> and <code class="prettyprint">packets</code>), until enough time has passed (300 seconds in this example):</p>

<pre class="prettyprint">
DEFINE total AS
  FROM inbound, outbound
  SELECT
    source, iface,
    min first AS first, max last AS last,
    sum bytes AS bytes, sum packets AS packets
  GROUP BY source, iface
  COMMIT AFTER out.last - out.first &gt; 300
  EVENT STARTING AT first AND STOPPING AT last;
</pre>

<p>It might be the first time you see a FROM clause with more that one function.  You are allowed to read from several functions as long as all these functions output (at least) all the fields that your function needs (with the same type).</p>

<p>You could plot the "bytes" or "packets" field of this function to get the total traffic reaching any interface.</p>

<p>For convenience let's rather compute the number of packets and bytes _per seconds_ instead:</p>

<pre class="prettyprint">
DEFINE total AS
  FROM inbound, outbound
  SELECT
    source, iface,
    min first AS first, max last AS last,
    sum bytes / (out.last - out.first) AS bytes_per_secs,
    sum packets / (out.last - out.first) AS packets_per_secs
  GROUP BY source, iface
  COMMIT AFTER out.last - out.first &gt; 300
  EVENT STARTING AT first AND STOPPING AT last;
</pre>

<p>Notice the prefix in <code class="prettyprint">out.first</code> and <code class="prettyprint">out.last</code> to identify the computed <code class="prettyprint">first</code> and <code class="prettyprint">last</code> from the output tuple ; without the prefix Ramen would have used the <code class="prettyprint">first</code> and <code class="prettyprint">last</code> fields from the input tuple instead of the result of the <code class="prettyprint">min</code>/<code class="prettyprint">max</code> aggregation functions, as the input tuple (<code class="prettyprint">in</code>) is the default when the same field can have several origins.</p>

<p>Now that we have the bandwidth per interface every 5 minutes, it is easy to signal when the traffic is outside the expected bounds for too long.  But we can do a bit better. Let's append this to <code class="prettyprint">traffic.ramen</code>:</p>

<pre class="prettyprint">
DEFINE traffic_alert AS
  FROM total
  SELECT
    source, iface,
    (last - first) / 2 AS time,
    bytes_per_secs,
    5-ma locally (bytes_per_secs &lt; 100 OR bytes_per_secs &gt; 8e3) &gt;= 4 AS firing
  GROUP BY source, iface
  COMMIT AND KEEP ALL WHEN COALESCE (out.firing <> previous.firing, false)
  NOTIFY "http://imaginary-alerting.com/notify?firing=${firing}&title=Traffic%20on%20${source}%2F${iface}&time=${time}";
</pre>

<p>Notice the definition of firing: instead of merely fire whenever the average traffic over 5 minutes is outside the range, we do this enigmatic "5-ma" dance. "5-ma" is actually a function that performs a moving average, ie. the average of the last 5 values. In order to average boolean values those will be converted into floats (1 for true and 0 for false as usual). So if the average of the last 5 values is above or equal to 4 that means at least 4 of the latests 5 values were true. Therefore, at the expense of a bit more latency, we can skip over a flapping metric.</p>

<p>NOTE: of course there are also functions for <code class="prettyprint">2-ma</code>, <code class="prettyprint">3-ma</code> and so on. This is just syntactic sugar.</p>

<p>The next enigmatic bit is the "locally" keyword. This is a function modifier that means that instead of storing it's temporary state globally the "5-ma" function should have one such state per group ; in other words, instead of computing the average over the last 5 incoming tuples regardless of their key, it should compute the average over the last 5 tuples aggregated into the same group.  Some functions default to having a global context while some default to have a local context. If unsure, add either <code class="prettyprint">locally</code> or <code class="prettyprint">globally</code> after any stateful function.</p>

<h3>Alerting on link down</h3>

<p>Alerting on link down might seems easy - isn't it a special case of the above, when we test for <code class="prettyprint">bytes_per_secs = 0</code> ?  This won't work for a very interesting reason: When there is no traffic at all on an interface, switches will not send a netflow message with zero valued counters. Instead they will not send anything at all, thus stalling the stream processor. To detect link down, therefore, we need some timeout.</p>

<p>Assuming we will still receive some netflows even when one link is down, the easier solution seems to compare the last time of each group with the latest input tuple time, each time a tuple is received, like so:</p>

<pre class="prettyprint">
DEFINE link_down_alert AS
  FROM traffic/total
  SELECT source, iface, max last
  GROUP BY source, iface
  COMMIT AND KEEP ALL WHEN in.last - max_last &gt; 300
  NOTIFY "http://imaginary-alerting.com/notify?text=link%20${source}%2F${iface}%20is%20down";
</pre>

<p>...and you have it!</p>

<p>If you have many interfaces, comparing each group with each incoming netflow might not be very efficient though. Maybe Ramen should provide a proper timeout feature, either based on actual wall clock time or on event time?</p>

<p>You should now be able to survive given only the <a href="language_reference.html">language reference manual</a>.</p>


  <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?lang=sql,shell"></script>

</body>
</html>
